{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcv2\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mface_recognition\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39m# Imagen a comparar\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "\n",
    "# Imagen a comparar\n",
    "image = cv2.imread(\"Images/yo.jpg\")\n",
    "face_loc = face_recognition.face_locations(image)[0]\n",
    "#print(\"face_loc:\", face_loc)\n",
    "face_image_encodings = face_recognition.face_encodings(image, known_face_locations=[face_loc])[0]\n",
    "print(\"face_image_encodings:\", face_image_encodings)\n",
    "'''\n",
    "cv2.rectangle(image, (face_loc[3], face_loc[0]), (face_loc[1], face_loc[2]), (0, 255, 0))\n",
    "cv2.imshow(\"Image\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()'''\n",
    "\n",
    "######################################################################################\n",
    "# Video Streaming\n",
    "\n",
    "cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "\n",
    "while True:\n",
    "     ret, frame = cap.read()\n",
    "     if ret == False: break\n",
    "     frame = cv2.flip(frame, 1)\n",
    "\n",
    "     face_locations = face_recognition.face_locations(frame)\n",
    "     if face_locations != []:\n",
    "          for face_location in face_locations:\n",
    "               face_frame_encodings = face_recognition.face_encodings(frame, known_face_locations=[face_location])[0]\n",
    "               result = face_recognition.compare_faces([face_frame_encodings], face_image_encodings)\n",
    "               print(\"Result:\", result)\n",
    "\n",
    "               if result[0] == True:\n",
    "                    text = \"Encontrado\"\n",
    "                    color = (125, 220, 0)\n",
    "               else:\n",
    "                    text = \"Desconocido\"\n",
    "                    color = (50, 50, 255)\n",
    "\n",
    "               cv2.rectangle(frame, (face_location[3], face_location[2]), (face_location[1], face_location[2] + 30), color, -1)\n",
    "               cv2.rectangle(frame, (face_location[3], face_location[0]), (face_location[1], face_location[2]), color, 2)\n",
    "               cv2.putText(frame, text, (face_location[3], face_location[2] + 20), 2, 0.7, (255, 255, 255), 1)\n",
    "\n",
    "\n",
    "     cv2.imshow(\"Frame\", frame)\n",
    "     k = cv2.waitKey(1)\n",
    "     if k == 27 & 0xFF:\n",
    "          break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
